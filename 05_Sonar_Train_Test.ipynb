{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드 및 확인\n",
    "df = pd.read_csv('../dataset/sonar.csv', header=None)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "# 피처 데이터, 타깃 데이터 분리\n",
    "X = dataset[:, 0:60]\n",
    "Y_obj = dataset[:, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "# 학습 셋과 테스트 셋의 구분\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0135, 0.0045, 0.0051, ..., 0.0028, 0.003 , 0.003 ],\n",
       "       [0.0293, 0.0644, 0.039 , ..., 0.016 , 0.0095, 0.0011],\n",
       "       [0.024 , 0.0218, 0.0324, ..., 0.0019, 0.0066, 0.0023],\n",
       "       ...,\n",
       "       [0.0228, 0.0106, 0.013 , ..., 0.0045, 0.0063, 0.0039],\n",
       "       [0.0373, 0.0281, 0.0232, ..., 0.0054, 0.0085, 0.006 ],\n",
       "       [0.018 , 0.0444, 0.0476, ..., 0.005 , 0.0073, 0.0022]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train 피처는 'float32' 타입으로 만들어줘야 학습이 가능\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.90e-03, 8.60e-03, 5.50e-03, ..., 5.80e-03, 5.90e-03, 3.20e-03],\n",
       "       [2.29e-02, 3.69e-02, 4.00e-03, ..., 2.90e-03, 1.04e-02, 1.63e-02],\n",
       "       [4.42e-02, 4.77e-02, 4.90e-03, ..., 1.05e-02, 5.90e-03, 1.05e-02],\n",
       "       ...,\n",
       "       [3.15e-02, 2.52e-02, 1.67e-02, ..., 3.50e-03, 1.00e-04, 5.50e-03],\n",
       "       [4.28e-02, 5.55e-02, 7.08e-02, ..., 8.40e-03, 1.13e-02, 4.90e-03],\n",
       "       [2.39e-02, 1.89e-02, 4.66e-02, ..., 2.60e-03, 3.60e-03, 2.40e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test 피처도 'float32' 타입으로 만들어준다.\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 60)\n",
      "(63, 60)\n",
      "(145,)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0135, 0.0045, 0.0051, ..., 0.0028, 0.003 , 0.003 ],\n",
       "       [0.0293, 0.0644, 0.039 , ..., 0.016 , 0.0095, 0.0011],\n",
       "       [0.024 , 0.0218, 0.0324, ..., 0.0019, 0.0066, 0.0023],\n",
       "       ...,\n",
       "       [0.0228, 0.0106, 0.013 , ..., 0.0045, 0.0063, 0.0039],\n",
       "       [0.0373, 0.0281, 0.0232, ..., 0.0054, 0.0085, 0.006 ],\n",
       "       [0.018 , 0.0444, 0.0476, ..., 0.005 , 0.0073, 0.0022]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = Sequential()                                    \n",
    "model.add(Dense(24,  input_dim=60, activation='relu'))  # 입력층 노드 수 60개(relu)\n",
    "                                                        # 은닉층1 노드 수 24개(relu)\n",
    "model.add(Dense(10, activation='relu'))                 # 은닉층2 노드 수 10개(relu)\n",
    "model.add(Dense(1, activation='sigmoid'))               # 출력층 노드 수 1개(sigmoid로 이진 분류)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 0s 744us/step - loss: 0.7022 - accuracy: 0.4759\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.6870 - accuracy: 0.5448\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 780us/step - loss: 0.6774 - accuracy: 0.5586\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 739us/step - loss: 0.6614 - accuracy: 0.6276\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 668us/step - loss: 0.6484 - accuracy: 0.7172\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.6365 - accuracy: 0.6966\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 878us/step - loss: 0.6165 - accuracy: 0.6828\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 821us/step - loss: 0.5939 - accuracy: 0.7517\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.5688 - accuracy: 0.7241\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.5470 - accuracy: 0.7655\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 756us/step - loss: 0.5193 - accuracy: 0.7931\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.5043 - accuracy: 0.8000\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 910us/step - loss: 0.4889 - accuracy: 0.7724\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.4660 - accuracy: 0.7862\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 760us/step - loss: 0.4521 - accuracy: 0.7793\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.4343 - accuracy: 0.8207\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 841us/step - loss: 0.4246 - accuracy: 0.8276\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 792us/step - loss: 0.4073 - accuracy: 0.8276\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 809us/step - loss: 0.4087 - accuracy: 0.8345\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 787us/step - loss: 0.3863 - accuracy: 0.8414\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.3754 - accuracy: 0.8552\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 822us/step - loss: 0.3695 - accuracy: 0.8690\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 862us/step - loss: 0.3569 - accuracy: 0.8552\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 805us/step - loss: 0.3476 - accuracy: 0.8621\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 899us/step - loss: 0.3510 - accuracy: 0.8414\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 904us/step - loss: 0.3379 - accuracy: 0.8828\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 861us/step - loss: 0.3280 - accuracy: 0.8621\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8966\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 663us/step - loss: 0.3147 - accuracy: 0.8759\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.3156 - accuracy: 0.8966\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 950us/step - loss: 0.3139 - accuracy: 0.8690\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 616us/step - loss: 0.3026 - accuracy: 0.8828\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 624us/step - loss: 0.2916 - accuracy: 0.8759\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 604us/step - loss: 0.2878 - accuracy: 0.8828\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 550us/step - loss: 0.2869 - accuracy: 0.9034\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 762us/step - loss: 0.2732 - accuracy: 0.8966\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 652us/step - loss: 0.2682 - accuracy: 0.9103\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 625us/step - loss: 0.2680 - accuracy: 0.9034\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 655us/step - loss: 0.2578 - accuracy: 0.9241\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 597us/step - loss: 0.2665 - accuracy: 0.9034\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 637us/step - loss: 0.2579 - accuracy: 0.9172\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.2519 - accuracy: 0.9103\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 908us/step - loss: 0.2563 - accuracy: 0.8966\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 778us/step - loss: 0.2428 - accuracy: 0.9034\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 857us/step - loss: 0.2335 - accuracy: 0.9103\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 810us/step - loss: 0.2304 - accuracy: 0.9172\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 713us/step - loss: 0.2223 - accuracy: 0.9310\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 871us/step - loss: 0.2162 - accuracy: 0.9241\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2111 - accuracy: 0.9172\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 798us/step - loss: 0.2230 - accuracy: 0.9379\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 774us/step - loss: 0.2161 - accuracy: 0.9241\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 816us/step - loss: 0.2076 - accuracy: 0.9448\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.2016 - accuracy: 0.9310\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 872us/step - loss: 0.1914 - accuracy: 0.9448\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 735us/step - loss: 0.1997 - accuracy: 0.9310\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9517\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 875us/step - loss: 0.1841 - accuracy: 0.9310\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 758us/step - loss: 0.1838 - accuracy: 0.9448\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 782us/step - loss: 0.1754 - accuracy: 0.9517\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 772us/step - loss: 0.1735 - accuracy: 0.9448\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 833us/step - loss: 0.1684 - accuracy: 0.9310\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 794us/step - loss: 0.1676 - accuracy: 0.9517\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 841us/step - loss: 0.1626 - accuracy: 0.9448\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 684us/step - loss: 0.1551 - accuracy: 0.9586\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 743us/step - loss: 0.1638 - accuracy: 0.9517\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 780us/step - loss: 0.1548 - accuracy: 0.9586\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.1402 - accuracy: 0.9724\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.1465 - accuracy: 0.9586\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 619us/step - loss: 0.1445 - accuracy: 0.9724\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 691us/step - loss: 0.1579 - accuracy: 0.9586\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 682us/step - loss: 0.1332 - accuracy: 0.9655\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 729us/step - loss: 0.1304 - accuracy: 0.9724\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.1455 - accuracy: 0.9517\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.1264 - accuracy: 0.9724\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 669us/step - loss: 0.1243 - accuracy: 0.9793\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 686us/step - loss: 0.1349 - accuracy: 0.9655\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 751us/step - loss: 0.1288 - accuracy: 0.9655\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 635us/step - loss: 0.1255 - accuracy: 0.9655\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 812us/step - loss: 0.1184 - accuracy: 0.9793\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 766us/step - loss: 0.1115 - accuracy: 0.9793\n",
      "Epoch 81/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 711us/step - loss: 0.1090 - accuracy: 0.9793\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 775us/step - loss: 0.1240 - accuracy: 0.9655\n",
      "Epoch 83/130\n",
      "29/29 [==============================] - 0s 606us/step - loss: 0.1201 - accuracy: 0.9586\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 752us/step - loss: 0.1066 - accuracy: 0.9793\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 704us/step - loss: 0.0986 - accuracy: 0.9862\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0984 - accuracy: 0.9793\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 817us/step - loss: 0.0943 - accuracy: 0.9793\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 653us/step - loss: 0.0936 - accuracy: 0.9862\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 617us/step - loss: 0.0881 - accuracy: 0.9931\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 673us/step - loss: 0.0958 - accuracy: 0.9931\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 727us/step - loss: 0.0991 - accuracy: 0.9724\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 632us/step - loss: 0.0943 - accuracy: 0.9793\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 695us/step - loss: 0.0893 - accuracy: 0.9793\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 620us/step - loss: 0.0784 - accuracy: 0.9862\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 648us/step - loss: 0.0797 - accuracy: 0.9862\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 723us/step - loss: 0.0758 - accuracy: 0.9862\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 623us/step - loss: 0.0745 - accuracy: 0.9793\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 745us/step - loss: 0.0762 - accuracy: 0.9862\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 639us/step - loss: 0.0704 - accuracy: 0.9862\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 659us/step - loss: 0.0656 - accuracy: 0.9931\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 680us/step - loss: 0.0668 - accuracy: 0.9862\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 644us/step - loss: 0.0663 - accuracy: 0.9931\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 638us/step - loss: 0.0747 - accuracy: 0.9793\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 637us/step - loss: 0.0658 - accuracy: 0.9793\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 636us/step - loss: 0.0769 - accuracy: 0.9862\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 608us/step - loss: 0.0764 - accuracy: 0.9862\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 730us/step - loss: 0.0634 - accuracy: 0.9931\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 652us/step - loss: 0.0572 - accuracy: 0.9862\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 619us/step - loss: 0.0688 - accuracy: 0.9862\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 694us/step - loss: 0.0590 - accuracy: 0.9931\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 662us/step - loss: 0.0555 - accuracy: 0.9931\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 622us/step - loss: 0.0536 - accuracy: 0.9931\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 765us/step - loss: 0.0536 - accuracy: 0.9931\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 647us/step - loss: 0.0488 - accuracy: 0.9931\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 606us/step - loss: 0.0531 - accuracy: 0.9862\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 633us/step - loss: 0.0480 - accuracy: 0.9931\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 637us/step - loss: 0.0494 - accuracy: 0.9931\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 611us/step - loss: 0.0425 - accuracy: 0.9931\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 576us/step - loss: 0.0448 - accuracy: 0.9931\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 635us/step - loss: 0.0428 - accuracy: 0.9931\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 610us/step - loss: 0.0456 - accuracy: 0.9931\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 639us/step - loss: 0.0416 - accuracy: 0.9931\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 638us/step - loss: 0.0423 - accuracy: 0.9931\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 696us/step - loss: 0.0384 - accuracy: 0.9931\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 625us/step - loss: 0.0428 - accuracy: 0.9862\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 618us/step - loss: 0.0406 - accuracy: 0.9931\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 651us/step - loss: 0.0362 - accuracy: 0.9931\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 620us/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 641us/step - loss: 0.0354 - accuracy: 0.9931\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 757us/step - loss: 0.0412 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb79863c490>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(X_train, Y_train, epochs=130, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 859us/step - loss: 0.7783 - accuracy: 0.8413\n",
      "\n",
      " Test Accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋에 모델 적용\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 정확도가 0.8571이 나온다. (앞 예제에서 학습셋으로 테스트 했더니 1.0 정확도(과적합)가 나왔던 것과 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
